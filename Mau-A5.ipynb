{
 "cells": [
  {
   "attachments": {
    "hanoi.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforced Learning - Temporal Difference\n",
    "### Josh Mau\n",
    "\n",
    "## Overview\n",
    "In this notebook I have implemented the Temporal Difference method for reinforced learning. This algorithm was used to teach the program how to solve the Towers of Hanoi puzzel. \n",
    "\n",
    "## Description of the puzzle\n",
    "In towers of hanoi, there are 3 \"towers\" or pegs which can contain discs. The puzzle start state is with all three discs on the far left tower. While the playing the game, no disc of a large size can be placed on top of a smaller disc and only one disc can be moved at a time. The goal state is a mirror image of the start state except all discs are on the third pegs\n",
    "![hanoi.png](attachment:hanoi.png)\n",
    "\n",
    "                        (this image from: http://mathworld.wolfram.com/TowerofHanoi.html)\n",
    "                        \n",
    "There is no real limit to the number of discs that can be used, but the minimum solutions is 2^(number of discs) -1 as can be seen below in the examples, using 3 discs, 2^3 -1 = 7 which is what the program converges on.\n",
    "\n",
    "## Implementation\n",
    "The follow code contains implementations for the following methods:\n",
    "* `printState(state)`: Used as a visual description of the current state of the puzzel\n",
    "* `validMoves(state)`: Returns list of all valid moves. These lists are of length 2, the 0 index is which tower to move the top element of, and the 1st index is which tower to move to. This method contains error checking when trying to move a disc of larger size onto a disc of a smaller size, and when trying to move a disc to a \"full\" tower (ideally should never occur)\n",
    "* `makeMove(state, move)`: This method executes a move on the current state of the puzzel and returns the new state\n",
    "* `trainQ(nRepetitions, learningRate, epsilonDecayFactor, validMovesF, makeMoveF)`: This function trains the computer on playing Towers of Hanoi. Parameters include\n",
    "    * **nRepetitions**: How many repititions the algorithm should run to find the best Q\n",
    "    * **learningRate**: How fast the machine will learn\n",
    "    * **epsilonDecayFactor**: How fast epsilon will decay - if too small, not enough moves will be explored\n",
    "    \n",
    "* `epsilonGreedy(epsilon, Q, state)`: Determines whether a random move will be made, or the smallest Q move. As epsilon decays, less random moves will be taken and more greedy moves will be taken.\n",
    "* `greedy(Q, state)`: Similar to epsilonGreedy except there's no greedy choice since the Q table is already full, it will always take the lowest Q from the current state\n",
    "* `stateMoveTuple(state, move)`: Used to convert state list and move list to a tuple so it can be used as a key the the Q dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal Difference machine learning\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "def printState(state):\n",
    "    oneC = 0\n",
    "    twoC = 0\n",
    "    threeC = 0\n",
    "    for i in range(3,0,-1):\n",
    "        temp = []\n",
    "        if len(state[0]) >= i and len(state[0]) > 0:\n",
    "            print(state[0][oneC], end=\"\")\n",
    "            print(\" \", end=\"\")\n",
    "            oneC += 1\n",
    "        else:\n",
    "            print(\" \", end=\"\")  \n",
    "        if len(state[1]) >= i and len(state[1]) > 0:\n",
    "            print(state[1][twoC], end=\"\")\n",
    "            print(\" \", end=\"\")\n",
    "            twoC += 1\n",
    "        else:\n",
    "            print(\" \", end=\"\")  \n",
    "        if len(state[2]) >= i and len(state[2]) > 0:\n",
    "            print(state[2][threeC], end=\"\")\n",
    "            print(\" \", end=\"\")\n",
    "            threeC += 1\n",
    "        else:\n",
    "            print(\" \", end=\"\")  \n",
    "        print()\n",
    "    print(\"=====\")\n",
    "\n",
    "\n",
    "def validMoves(state):\n",
    "    t1 = state[0]   # Tower 1\n",
    "    t2 = state[1]   # Tower 2\n",
    "    t3 = state[2]   # Tower 3\n",
    "    moves = []      # initialize valid moves to empty\n",
    "    t1top = 4\n",
    "    t2top = 4\n",
    "    t3top = 4\n",
    "\n",
    "    if len(t1) > 0: # if tower 1 not full\n",
    "        t1top = t1[0]\n",
    "    if len(t2) > 0: # if tower 2 not full\n",
    "        t2top = t2[0]\n",
    "    if len(t3) > 0: # if tower 3 not full\n",
    "        t3top = t3[0]\n",
    "\n",
    "    if t1top < t2top:\n",
    "        moves.append([1,2])\n",
    "    if t1top < t3top:\n",
    "        moves.append([1,3])\n",
    "    if t2top < t1top:\n",
    "        moves.append([2,1])\n",
    "    if t2top < t3top:\n",
    "        moves.append([2,3])\n",
    "    if t3top < t1top: \n",
    "        moves.append([3,1])\n",
    "    if t3top < t2top:\n",
    "        moves.append([3,2])\n",
    "\n",
    "    return moves\n",
    "    \n",
    "\n",
    "def makeMove(state, move):\n",
    "    discToMove = state[move[0]-1][0]    # move[0]-1 for 0 based list\n",
    "    towerToMoveTo = move[1]-1\n",
    "    state[move[0]-1] = state[move[0]-1][1:] # remove item in tower\n",
    "    state[towerToMoveTo].insert(0, discToMove)\n",
    "    return state\n",
    "\n",
    "def trainQ(nRepetitions, learningRate, epsilonDecayFactor, validMovesF, makeMoveF): \n",
    "    Q = {}\n",
    "    epsilon = 1.0\n",
    "    steps = []\n",
    "\n",
    "    for num in range(nRepetitions):\n",
    "        epsilon *= epsilonDecayFactor\n",
    "        state = [[1,2,3],[],[]]\n",
    "        stepCount = 0\n",
    "        oldstate = []\n",
    "        oldmove = []\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            stepCount += 1\n",
    "    \n",
    "            move = epsilonGreedy(epsilon, Q, state)\n",
    "            stateNew = []\n",
    "            stateNew.append(copy.copy(state[0]))\n",
    "            stateNew.append(copy.copy(state[1]))\n",
    "            stateNew.append(copy.copy(state[2]))\n",
    "            stateNew = makeMoveF(stateNew, move)\n",
    "\n",
    "            if stateMoveTuple(state, move) not in Q:\n",
    "                Q[stateMoveTuple(state, move)] = 1\n",
    "            else:\n",
    "                if stepCount > 1:\n",
    "                    oldStateTuple = stateMoveTuple(oldstate, oldmove)\n",
    "                    Q[oldStateTuple] += learningRate * (-1 + Q[stateMoveTuple(state, move)] - Q[oldStateTuple])\n",
    "            oldstate, oldmove = state, move\n",
    "            state = stateNew\n",
    "            if state == [[],[],[1,2,3]]:\n",
    "                done = True\n",
    "                Q[stateMoveTuple(state,move)] = -1\n",
    "\n",
    "        steps.append(stepCount)\n",
    "    return Q, steps\n",
    "\n",
    "\n",
    "def testQ(Q, maxSteps, validMovesF, makeMoveF):\n",
    "    state = [[1,2,3],[],[]]\n",
    "    allStates = []\n",
    "    for i in range(maxSteps):\n",
    "        move = greedy(Q, state)\n",
    "        stateNew = []\n",
    "        stateNew.append(copy.copy(state[0]))\n",
    "        stateNew.append(copy.copy(state[1]))\n",
    "        stateNew.append(copy.copy(state[2]))\n",
    "        stateNew = makeMoveF(stateNew, move)\n",
    "        if state == [[],[],[1,2,3]]:\n",
    "            break\n",
    "        allStates.append(stateNew)\n",
    "        state = stateNew\n",
    "    return allStates\n",
    "\n",
    "def greedy(Q, state):\n",
    "    moves = validMoves(state)\n",
    "    Qs = np.array([Q.get(stateMoveTuple(state, m), 1) for m in moves]) \n",
    "    return moves[ np.argmax(Qs) ]\n",
    "\n",
    "def epsilonGreedy(epsilon, Q, state):\n",
    "    moves = validMoves(state)\n",
    "    if np.random.uniform() < epsilon:\n",
    "        # Random Move\n",
    "        return moves[ np.random.choice(len(moves))]\n",
    "    else:\n",
    "        # Greedy Move\n",
    "        Qs = np.array([Q.get(stateMoveTuple(state, m), 1) for m in moves]) \n",
    "        return moves[ np.argmax(Qs) ]\n",
    "\n",
    "def stateMoveTuple(state, move):\n",
    "    a = tuple(state[0])\n",
    "    b = tuple(state[1])\n",
    "    c = tuple(state[2])\n",
    "    return ((a,b,c), tuple(move))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples\n",
    "Running trainQ and testQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table of step counts: [49, 44, 27, 120, 40, 37, 14, 22, 20, 34, 22, 7, 46, 31, 10, 13, 17, 13, 36, 10, 13, 7, 21, 7, 7, 12, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n",
      "Length of Q Table: 77\n"
     ]
    }
   ],
   "source": [
    "Q, steps= trainQ(50, 0.5, 0.7, validMoves, makeMove)\n",
    "print(\"Table of step counts: \", end=\"\")\n",
    "print(steps)\n",
    "print(\"Length of Q Table: \", end=\"\")\n",
    "print(len(Q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Length of solution: 7\n",
      "   \n",
      "2   \n",
      "3  1 \n",
      "=====\n",
      "   \n",
      "   \n",
      "3 2 1 \n",
      "=====\n",
      "   \n",
      " 1  \n",
      "3 2  \n",
      "=====\n",
      "   \n",
      " 1  \n",
      " 2 3 \n",
      "=====\n",
      "   \n",
      "   \n",
      "1 2 3 \n",
      "=====\n",
      "   \n",
      "  2 \n",
      "1  3 \n",
      "=====\n",
      "  1 \n",
      "  2 \n",
      "  3 \n",
      "=====\n"
     ]
    }
   ],
   "source": [
    "path = testQ(Q, 10, validMoves, makeMove)\n",
    "print()\n",
    "print(\"Length of solution: \", end=\"\")\n",
    "print(len(path))\n",
    "for p in path:\n",
    "    printState(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "The above results are produced when running trainQ and testQ. The first set of results is the step count and the total size of the Q table. The step count are per iteration, showing how the program learns the best path as it begins to converge on 7 (the true minimum) at around the half way point. \n",
    "\n",
    "The second set of results is from testQ. This uses the Q table produced above and always takes the greedy step. It can solve this puzzel in 7 steps and the Q table results allow.\n",
    "\n",
    "*The above depiction of the final state is skewed, it is on the third peg, it's just two spaces over*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing validMoves([[1], [2], [3]])\n",
      "\n",
      "--- 10/10 points. Correctly returned [[1, 2], [1, 3], [2, 3]]\n",
      "\n",
      "Testing validMoves([[], [], [1, 2, 3]])\n",
      "\n",
      "--- 10/10 points. Correctly returned [[3, 1], [3, 2]]\n",
      "\n",
      "Testing makeMove([[], [], [1, 2, 3]], [3, 2])\n",
      "\n",
      "--- 10/10 points. Correctly returned [[], [1], [2, 3]]\n",
      "\n",
      "Testing makeMove([[2], [3], [1]], [1, 2])\n",
      "\n",
      "--- 10/10 points. Correctly returned [[], [2, 3], [1]]\n",
      "\n",
      "Testing   Q, steps = trainQ(1000, 0.5, 0.7, validMoves, makeMove).\n",
      "\n",
      "--- 10/10 points. Q dictionary has correct number of entries.\n",
      "\n",
      "--- 10/10 points. The mean of the number of steps is 7.488 which is correct.\n",
      "\n",
      "Testing   path = testQ(Q, 20, validMoves, makeMove).\n",
      "\n",
      "--- 20/20 points. Correctly returns path of length 7, less than 10.\n",
      "\n",
      "A5 Execution Grade is 80/80\n",
      "\n",
      " Remaining 20 points will be based on your text describing the trainQ and test! functions.\n",
      "\n",
      "A5 FINAL GRADE is __/100\n"
     ]
    }
   ],
   "source": [
    "%run -i A5grader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
