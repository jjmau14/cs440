{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A3: A\\*, IDS, and Effective Branching Factor\n",
    "\n",
    "### Josh Mau / jjmau14\n",
    "\n",
    "\n",
    "In this assignment, I have implemented the Recursive Best-First Search implementation of the A\\* algorithm. The base of the A\\* algorithm was derived from Ph.D. of Computer Science, Chuck Anderson and is available at \n",
    "* http://nbviewer.jupyter.org/url/www.cs.colostate.edu/~anderson/cs440/notebooks/07%20Informed%20Search.ipynb \n",
    "\n",
    "This assignment compares three different heuristic functions used by the A\\* algorithm to the `iterativeDeepeningSearch` algorithm implemented in the previous assignment. These heuristics and algorithms are compared by reporting the total number of nodes expanded, the depth of expansion, and the EBF (Effective Branching Factor) value of each. The EBF is essentially the average or expected number of successor nodes generated by the typical node for the given algorithm. \n",
    "\n",
    "### Implementation of EBF\n",
    "Binary search was used to determine the EBF for any given algorithm. An initial starting position is determined given the range of possible values based on the depth and how many nodes were expanded. The following equation is then used to create a guess as to what the actual Effective Branching Factor may be (the value of **b**) and determining its proximity to **d** (depth of search). If the value if **b** is within the valid proximity of **d** (based on the precision passed to the function -- defaults to 0.01), then **b** is accepted as the EFB of the algorithm.\n",
    "\n",
    "$$ \\frac{1-b^{d+1}}{1-b}$$\n",
    "\n",
    "The purpose of this function is to determine the effectiveness of the heuristic function used in the the A\\* search algoritm.\n",
    "\n",
    "### Functions implemented\n",
    "The main functions used in this notebook are the following:\n",
    "\n",
    "* `aStarSearch(startState, actionsF, takeActionF, goalTestF, hF)`\n",
    "* `iterativeDeepeningSearch(startState, goalState, actionsF, takeActionF, maxDepth)`\n",
    "* `ebf(nNodes, depth, precision=0.01)`\n",
    "   \n",
    "Additional functions include those which define heuristic functions, or handle rules for the 8-puzzle game such as validity of moves, testing for goal state, and committing moves to the board. These functions are as follows:\n",
    "\n",
    "* `actionsF_8p(state)`: returns a list of all possible valid actions given the current location (state) \n",
    "* `takeActionsF_8p(state, action)`: handles executing actions and updating the current state of the puzzle\n",
    "* `goalTestF_8p(state, goal)`: returns a boolean value: is the puzzle complete or not\n",
    "   \n",
    "The main function of this assignment is `runExperiment(goalState1, goalState2, goalState3, [h1, h2, h3])`. This function takes a list of 3 valid goalStates given a previously specified startState [1, 2, 3, 4, 0, 5, 6, 7, 8]. The function first runs `iterativeDeepeningSearch` for each of the three goal states and produces the total nodes expanded, the depth of expansion, and the EBF. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heuristic Functions\n",
    "\n",
    "For `aStarSearch`, the following heuristics were used. \n",
    "\n",
    "  * `h1_8p(state, goal)`: $h(state, goal) = 0$, for all states $state$ and all goal states $goal$,\n",
    "  * `h2_8p(state, goal)`: $h(state, goal) = m$, where $m$ is the Manhattan distance that the blank is from its goal position,\n",
    "  * `h3_8p(state, goal)`: Definition and proof below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation of Heuristic 3\n",
    "The 3rd heuristic is uses the 0 based index to return a heuristic. Since the table is set configured with indexes:\n",
    "\n",
    "$$\n",
    "\\begin{array}{ccc}\n",
    "0 & 1 & 2\\\\\n",
    "3 & 4 & 5\\\\\n",
    "6 & 7 & 8\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "the heuristic function will get the index of 0 in the state, and the index of 0 in the goal state. The two indexes are then subtracted from each other in no particular order, and the absolute value of this calulation (using math.fabs) is then divided by 2 using *specifically* integer division. This avoids overestimation. An example follows the first is the example current state, and the second is the example goal state:\n",
    "\n",
    "$$\n",
    "\\begin{array}{ccccccccccc}\n",
    "1 & 2 & 3  & ~~~~ & 1 & 2 & 3\\\\\n",
    "4 & 0 & 5  & & 4 & 7 & 5\\\\\n",
    "6 & 7 & 8 &  & 6 & 0 & 8\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "The index of 0 in the current state is index 4. The index of 0 in the goal state is 7. In this case, 7 is subtracted from 4, producing -3. ABS(-3) is 3. This result is then divided by 2 using integer division producing a result of 1.\n",
    "\n",
    "1 is not an overestimation since the actual shortest path is 1. Another example follows:\n",
    "\n",
    "$$\n",
    "\\begin{array}{ccccccccccc}\n",
    "0 & 2 & 3  & ~~~~ & 2 & 3 & 5\\\\\n",
    "4 & 1 & 5  & & 4 & 5 & 8\\\\\n",
    "6 & 7 & 8 &  & 6 & 7 & 0\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "In this case, the index of 0 in the current state is 0, and the index of 0 in the goal state is 8. These two numbers would be subtracted and the absolute value will be taken resulting in 8 and a total distance. 8 is clearly an overestimation hence division by 2. The case in which the 0's are in the corners is the maximum case, there cannot be a greater distance between the two. 4 would be the result of the heuristic in this case which is the actual shortest path. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## States used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following 8-Puzzel was used to perform all tests in this assignment\n",
    "\n",
    "$$\n",
    "\\begin{array}{ccc}\n",
    "1 & 2 & 3\\\\\n",
    "4 & 0 & 5\\\\\n",
    "6 & 7 & 8\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "\n",
    "These known valid goal states are passed to the `runExperiment` function which tests each algorithm on each goal state and reports back stats\n",
    "\n",
    "$$\n",
    "\\begin{array}{ccccccccccc}\n",
    "1 & 2 & 3  & ~~~~ & 1 & 2 & 3  &  ~~~~ & 1 & 0 &  3\\\\\n",
    "4 & 0 & 5  & & 4 & 5 & 8  & & 4 & 5 & 8\\\\\n",
    "6 & 7 & 8 &  & 6 & 0 & 7  & & 2 & 6 & 7\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code \n",
    "Contains each function definition and test cases in the main "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[1, 2, 3, 4, 0, 5, 6, 7, 8]\t\t[1, 2, 3, 4, 5, 8, 6, 0, 7]\t\t[1, 0, 3, 4, 5, 8, 2, 6, 7]\t\n",
      "Algorithm      Depth   Nodes   EBF\t\t  Depth   Nodes   EBF\t\t\t Depth   Nodes   EBF\n",
      "\tIDS\t0\t0\t0\t\t3\t43\t3.101\t\t\t11\t225850\t2.949\n",
      "\tA*H1\t0\t0\t0\t\t3\t116\t4.477\t\t\t11\t643246\t3.18\n",
      "\tA*H2\t0\t0\t0\t\t3\t51\t3.313\t\t\t11\t100046\t2.731\n",
      "\tA*H3\t0\t0\t0\t\t3\t32\t2.721\t\t\t11\t214662\t2.941\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def iterativeDeepeningSearch(startState, goalState,\n",
    "                             actionsF, takeActionF, maxDepth):\n",
    "\tglobal itsTotal\n",
    "\tglobal itsDepth\n",
    "\titsTotal = 0\n",
    "\titsDepth = 0\n",
    "    \n",
    "\tfor depth in range(maxDepth):\n",
    "\t\tresult = depthLimitedSearch(startState, goalState,\n",
    "                                    actionsF, takeActionF, depth)\n",
    "\t\tif result is 'failure':\n",
    "\t\t\treturn 'failure'\n",
    "\t\tif result is not 'cutoff':\n",
    "\t\t\tresult.insert(0, startState)\n",
    "\t\t\titsDepth = depth\n",
    "\t\t\treturn result\n",
    "\treturn 'cutoff'\n",
    "\n",
    "\n",
    "def depthLimitedSearch(state, goalState,\n",
    "                       actionsF, takeActionF, depthLimit):\n",
    "\tglobal itsTotal\n",
    "\tif state == goalState:\n",
    "\t\treturn []\n",
    "\tif depthLimit == 0:\n",
    "\t\treturn 'cutoff'\n",
    "\tcutoffOccurred = False\n",
    "\tfor action in actionsF(state):\n",
    "\t\titsTotal += 1\n",
    "\t\tchildState = takeActionF(state, action)[0]\n",
    "\t\tresult = depthLimitedSearch(childState, goalState,\n",
    "                                    actionsF, takeActionF, depthLimit-1)\n",
    "\t\tif result is 'cutoff':\n",
    "\t\t\tcutoffOccurred = True\n",
    "\t\telif result is not 'failure':\n",
    "\t\t\tresult.insert(0, childState)\n",
    "\t\t\treturn result\n",
    "\tif cutoffOccurred:\n",
    "\t\treturn 'cutoff'\n",
    "\telse:\n",
    "\t\treturn 'failure'\n",
    "\n",
    "######################################################################\n",
    "# Eight Puzzle\n",
    "\n",
    "\n",
    "def findBlank_8p(s):\n",
    "\treturn iTorc(s.index(0))\n",
    "\n",
    "\n",
    "def actionsF_8p(state):\n",
    "\tr, c = findBlank_8p(state)\n",
    "\tactions = []\n",
    "\tif c > 0:\n",
    "\t\tactions.append(('left', 1))\n",
    "\tif c < 2:\n",
    "\t\tactions.append(('right',1))\n",
    "\tif r > 0:\n",
    "\t\tactions.append(('up',1))\n",
    "\tif r < 2:\n",
    "\t\tactions.append(('down',1))\n",
    "\treturn actions\n",
    "\n",
    "\n",
    "def takeActionF_8p(state, action):\n",
    "\timport copy\n",
    "\tstate = copy.deepcopy(state)\n",
    "\tr, c = findBlank_8p(state)\n",
    "\tdr = dc = 0\n",
    "\tif action[0] is 'left':\n",
    "\t\tdc -= 1\n",
    "\telif action[0] is 'right':\n",
    "\t\tdc += 1\n",
    "\telif action[0] is 'up':\n",
    "\t\tdr -= 1\n",
    "\telif action[0] is 'down':\n",
    "\t\tdr += 1\n",
    "\tnewr, newc = r+dr, c+dc\n",
    "\tsetTile(state, r, c, getTile(state, newr, newc))\n",
    "\tsetTile(state, newr, newc, 0)\n",
    "\treturn (state, 1)\n",
    "\n",
    "\n",
    "def goalTestF_8p(s, goalState):\n",
    "\treturn s == goalState\n",
    "\n",
    "\n",
    "def printPath_8p(start, goal, solutionPath):\n",
    "\tprint('\\n\\nPath from')\n",
    "\tprintState_8p(start)\n",
    "\tprint('  to')\n",
    "\tprintState_8p(goal)\n",
    "\tif solutionPath is 'cutoff':\n",
    "\t\tprint('was not found due to depth cutoff.')\n",
    "\telif solutionPath is 'failure':\n",
    "\t\tprint('cannot be found.')\n",
    "\telse:\n",
    "\t\tprint('  is', len(solutionPath), 'nodes long:')\n",
    "\t\tindent = 0\n",
    "\t\tfor s in solutionPath:\n",
    "\t\t\tprintState_8p(s, indent)\n",
    "\t\t\tprint()\n",
    "\t\t\tindent += 1\n",
    "\n",
    "\n",
    "def printState_8p(state, indent=0):\n",
    "\tst = list(map(str, state))\n",
    "\tst[st.index('0')] = '-'\n",
    "\tblanks = ' '*indent\n",
    "\tfor i in range(0, 9, 3):\n",
    "\t\tprint('{} {} {} {}'.format(blanks, st[0+i], st[1+i], st[2+i]))\n",
    "\n",
    "\n",
    "def rcToi(row, col):\n",
    "\treturn row*3+col\n",
    "\n",
    "\n",
    "def iTorc(i):\n",
    "\trow = i // 3\n",
    "\tcol = i - row*3\n",
    "\treturn (row, col)\n",
    "\n",
    "\n",
    "def setTile(state, row, col, tile):\n",
    "\tstate[rcToi(row, col)] = tile\n",
    "\treturn state\n",
    "\n",
    "\n",
    "def getTile(state, row, col):\n",
    "\treturn state[rcToi(row, col)]\n",
    "\n",
    "\n",
    "class Node:\n",
    "\tdef __init__(self, state, f=0, g=0 ,h=0):\n",
    "\t\tself.state = state\n",
    "\t\tself.f = f\n",
    "\t\tself.g = g\n",
    "\t\tself.h = h\n",
    "\tdef __repr__(self):\n",
    "\t\treturn \"Node(\" + repr(self.state) + \", f=\" + repr(self.f) + \", g=\" + repr(self.g) + \", h=\" + repr(self.h) + \")\"\n",
    "\n",
    "def ebf(nNodes, depth, precision=0.01):\n",
    "\tif nNodes == depth:\n",
    "\t\treturn 0\n",
    "\tif depth == 0:\n",
    "\t\treturn 1.0\n",
    "\tn = depth/2.0\n",
    "\tminVal = 0.0\n",
    "\tmaxVal = nNodes\n",
    "\ttotal = 0\n",
    "    \n",
    "\tminRange = nNodes - (nNodes*precision)\n",
    "\tmaxRange = nNodes + (nNodes*precision)\n",
    "  \n",
    "\twhile ( not(total > minRange and total < maxRange)):\n",
    "\t\t# 1 - (b^(d+1))/(1-b)\n",
    "\t\ttotal = ( (1.0-(n**(depth+1))) / (1.0-n) )\n",
    "\n",
    "\t\tif total < nNodes:\n",
    "\t\t\tminVal = n\n",
    "\t\t\tn = (n + maxVal) / 2.0\n",
    "      \n",
    "\t\tif total > nNodes:\n",
    "\t\t\tmaxVal = n\n",
    "\t\t\tn = (n + minVal) / 2.0\n",
    "      \n",
    "\treturn n\n",
    "      \n",
    "      \n",
    "        \n",
    "def aStarSearch(startState, actionsF, takeActionF, goalTestF, hF):\n",
    "\tglobal aStarCounter\n",
    "\tglobal aStarDepth\n",
    "\taStarDepth = 0\n",
    "\taStarCounter = 0\n",
    "\th = hF(startState)\n",
    "\tstartNode = Node(state=startState, f=0+h, g=0, h=h)\n",
    "\treturn aStarSearchHelper(startNode, actionsF, takeActionF, goalTestF, hF, float('inf'))\n",
    "\n",
    "def aStarSearchHelper(parentNode, actionsF, takeActionF, goalTestF, hF, fmax):\n",
    "\tglobal aStarCounter\n",
    "\tglobal aStarDepth\n",
    "\tif goalTestF(parentNode.state):\n",
    "\t\treturn ([parentNode.state], parentNode.g)\n",
    "\t## Construct list of children nodes with f, g, and h values\n",
    "\tactions = actionsF(parentNode.state)\n",
    "\t#print(actions)\n",
    "\tif not actions:\n",
    "\t\treturn (\"failure\", float('inf'))\n",
    "\tchildren = []\n",
    "\tfor action in actions:\n",
    "\t\taStarCounter += 1\n",
    "\t\t(childState, stepCost) = takeActionF(parentNode.state, action)\n",
    "\t\th = hF(childState)\n",
    "\t\tg = parentNode.g + stepCost\n",
    "\t\tf = max(h+g, parentNode.f)\n",
    "\t\tchildNode = Node(state=childState, f=f, g=g, h=h)\n",
    "\t\tchildren.append(childNode)\n",
    "\twhile True:\n",
    "\t\t# find best child\n",
    "\t\tchildren.sort(key = lambda n: n.f) # sort by f value\n",
    "\t\tbestChild = children[0]\n",
    "\t\tif bestChild.f > fmax:\n",
    "\t\t\treturn (\"failure\",bestChild.f)\n",
    "\t\t# next lowest f value\n",
    "\t\talternativef = children[1].f if len(children) > 1 else float('inf')\n",
    "\t\t# expand best child, reassign its f value to be returned value\n",
    "\t\tresult,bestChild.f = aStarSearchHelper(bestChild, actionsF, takeActionF, goalTestF,\n",
    "                                            hF, min(fmax,alternativef))\n",
    "\t\tif result is not \"failure\":\n",
    "\t\t\taStarDepth += 1\n",
    "\t\t\tresult.insert(0,parentNode.state)\n",
    "\t\t\treturn (result, bestChild.f)\n",
    "          \n",
    "def takeActionF_simple(state, action):\n",
    "\treturn action\n",
    "\n",
    "def goalTestF_simple(state, goal):\n",
    "\treturn state == goal\n",
    "\n",
    "def h_simple(state, goal):\n",
    "\treturn 0\n",
    "\n",
    "def h1_8p(state, goal):\n",
    "\treturn 1\n",
    " \n",
    "def h3_8p(state, goal):\n",
    "\tsIndex = state.index(0)\n",
    "\tgIndex = goal.index(0)\n",
    "\treturn math.fabs(sIndex - gIndex) / 2\n",
    "\t\n",
    "def h2_8p(state, goal):\n",
    "\tsIndex = state.index(0)\n",
    "\tgIndex = goal.index(0)\n",
    "\t\n",
    "\tc = columnDiff(sIndex, gIndex)\n",
    "\tr = rowDiff(sIndex, gIndex)\n",
    "\t\n",
    "\treturn c + r\n",
    "\t\n",
    "def columnDiff(s, g):\n",
    "\tsColumn = 0\n",
    "\tgColumn = 0\n",
    "\t\n",
    "\tif s == 0 or s == 3 or s == 6:\n",
    "\t\tsColumn = 0\n",
    "\telif s == 1 or s == 4 or s == 7:\n",
    "\t\tsColumn = 1\n",
    "\telse:\n",
    "\t\tsColumn = 2\n",
    "\t\t\n",
    "\tif g == 0 or g == 3 or g == 6:\n",
    "\t\tsColumn = 0\n",
    "\telif g == 1 or g == 4 or g == 7:\n",
    "\t\tgColumn = 1\n",
    "\telse:\n",
    "\t\tgColumn = 2\n",
    "\t\t\n",
    "\treturn math.fabs(gColumn - sColumn)\n",
    "\t\n",
    "\n",
    "def rowDiff(s, g):\n",
    "\tsRow = 0\n",
    "\tgRow = 0\n",
    "\t\n",
    "\tif s == 0 or s == 1 or s == 2:\n",
    "\t\tsRow = 0\n",
    "\telif s == 3 or s == 4 or s == 5:\n",
    "\t\tsRow = 1\n",
    "\telse:\n",
    "\t\tsRow = 2\n",
    "\t\t\n",
    "\tif g == 0 or g == 1 or g ==2:\n",
    "\t\tgRow = 0\n",
    "\telif g == 3 or g == 4 or g == 5:\n",
    "\t\tgRow = 1\n",
    "\telse:\n",
    "\t\tgRow = 2\n",
    "\t\t\n",
    "\treturn math.fabs(gRow - sRow)\n",
    "\n",
    "\n",
    "def runExperiment(goalState1, goalState2, goalState3, heuristics = []):\n",
    "\tglobal aStarDepth\n",
    "\tglobal aStarCounter\n",
    "\tstartState = [1, 2, 3, 4, 0, 5, 6, 7, 8]\n",
    "\tprint(\"\\t{}\\t\\t{}\\t\\t{}\\t\".format(goalState1, goalState2, goalState3))\n",
    "\tprint(\"Algorithm      Depth   Nodes   EBF\\t\\t  Depth   Nodes   EBF\\t\\t\\t Depth   Nodes   EBF\")\n",
    "  \n",
    "\t# Iterative Deepening\n",
    "\tl = iterativeDeepeningSearch(startState, goalState1, actionsF_8p, takeActionF_8p, 999999)\n",
    "\tprint(\"\\tIDS\\t{}\\t{}\\t{}\".format(itsDepth, itsTotal, round(ebf(itsTotal, itsDepth, 0.01), 3)), end='')\n",
    "  \n",
    "\tl = iterativeDeepeningSearch(startState, goalState2, actionsF_8p, takeActionF_8p, 999999)\n",
    "\tprint(\"\\t\\t{}\\t{}\\t{}\".format(itsDepth, itsTotal, round(ebf(itsTotal, itsDepth, 0.01), 3)), end='')\n",
    "  \n",
    "\tl = iterativeDeepeningSearch(startState, goalState3, actionsF_8p, takeActionF_8p, 999999)\n",
    "\tprint(\"\\t\\t\\t{}\\t{}\\t{}\".format(itsDepth, itsTotal, round(ebf(itsTotal, itsDepth, 0.01), 3)))\n",
    "\n",
    "\tcounter = 1\n",
    "\tfor H in heuristics:\n",
    "\t\taStarSearch(startState, actionsF_8p, takeActionF_8p, lambda s: goalTestF_simple(s, goalState1), lambda s: H(s, goalState1))\n",
    "\t\tprint(\"\\tA*H{}\\t{}\\t{}\\t{}\".format(counter, aStarDepth, aStarCounter, round(ebf(aStarCounter, aStarDepth, 0.01), 3)), end='')\n",
    "\t\t\n",
    "\t\taStarSearch(startState, actionsF_8p, takeActionF_8p, lambda s: goalTestF_simple(s, goalState2), lambda s: H(s, goalState2))\n",
    "\t\tprint(\"\\t\\t{}\\t{}\\t{}\".format(aStarDepth, aStarCounter, round(ebf(aStarCounter, aStarDepth, 0.01), 3)), end='')\n",
    "\t\t\n",
    "\t\taStarSearch(startState, actionsF_8p, takeActionF_8p, lambda s: goalTestF_simple(s, goalState3), lambda s: H(s, goalState3))\n",
    "\t\tprint(\"\\t\\t\\t{}\\t{}\\t{}\".format(aStarDepth, aStarCounter, round(ebf(aStarCounter, aStarDepth, 0.01), 3)))\n",
    "\t\tcounter += 1\n",
    "\t\t\n",
    "if __name__ == \"__main__\":\n",
    "\trunExperiment([1, 2, 3, 4, 0, 5, 6, 7, 8], [1, 2, 3, 4, 5, 8, 6, 0, 7], [1, 0, 3, 4, 5, 8, 2, 6, 7], [h1_8p, h2_8p, h3_8p])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above output is the table of stats produced by all three algorithms containing Depth, Number of Nodes expanded, and EBF for each of the three known end states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here is an example of EBF running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6494140625"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebf(10, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This provides that, on average, each node will generate ~1.65 successors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The smallest argument values should be a depth of 0, and 1 node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebf(1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following are example test cases for testing the EBF function\n",
    "* Results are assumed within a +/- 10% margin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9921875"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebf(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000009536743164"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebf(2, 1, precision=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.464426517486572"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebf(200000, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2350082397460938"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebf(200000, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a simple example using our usual simple graph search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing actionsF_8p([1, 2, 3, 4, 5, 6, 7, 0, 8])\n",
      "\n",
      "--- 5/5 points. Your actionsF_8p correctly returned [('left', 1), ('right', 1), ('up', 1)]\n",
      "\n",
      "Testing takeActionF_8p([1, 2, 3, 4, 5, 6, 7, 0, 8], (up, 1))\n",
      "\n",
      "--- 5/5 points. Your takeActionsF_8p correctly returned ([1, 2, 3, 4, 0, 6, 7, 5, 8], 1)\n",
      "\n",
      "Testing goalTestF_8p([1, 2, 3, 4, 5, 6, 7, 0, 8], [1, 2, 3, 4, 5, 6, 7, 0, 8])\n",
      "\n",
      "--- 5/5 points. Your goalTestF_8p correctly True\n",
      "\n",
      "Testing aStarSearch([1, 2, 3, 4, 5, 6, 7, 0, 8],\n",
      "                     actionsF_8p, takeActionF_8p,\n",
      "                     lambda s: goalTestF_8p(s, [0, 2, 3, 1, 4,  6, 7, 5, 8]),\n",
      "                     lambda s: h1_8p(s, [0, 2, 3, 1, 4,  6, 7, 5, 8]))\n",
      "\n",
      "--- 20/20 points. Your search correctly returned ([[1, 2, 3, 4, 5, 6, 7, 0, 8], [1, 2, 3, 4, 0, 6, 7, 5, 8], [1, 2, 3, 0, 4, 6, 7, 5, 8], [0, 2, 3, 1, 4, 6, 7, 5, 8]], 3)\n",
      "\n",
      "Testing iterativeDeepeningSearch([5, 2, 8, 0, 1, 4, 3, 7, 6], \n",
      "                                 [0, 2, 3, 1, 4,  6, 7, 5, 8],\n",
      "                                 actionsF_8p, takeActionF_8p, 10)\n",
      "\n",
      "--- 15/15 points. Your search correctly returned cutoff\n",
      "\n",
      "A3 Grade is 50/50\n"
     ]
    }
   ],
   "source": [
    "%run -i A3grader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
