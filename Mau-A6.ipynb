{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 6: Neural Networks\n",
    "Josh Mau\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "In this notebook, I have implemented a neural network running on data from the following source:\n",
    "* http://archive.ics.uci.edu/ml/machine-learning-databases/00374/energydata_complete.cs\n",
    "\n",
    "I have run two experiments on this neural network:\n",
    "* Regression\n",
    "* Classification\n",
    "\n",
    "Each neural network is trained multiple times and the results are compared.\n",
    "\n",
    "## References\n",
    "The following python scripts were obtained at http://www.cs.colostate.edu/~anderson/cs440/notebooks/nn2.tar and were authored by Dr. Chuck Anderson\n",
    "* neuralnetworks.py\n",
    "* scaledconjugategradient.py\n",
    "* mlutils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Neural Networks\n",
    "This function takes inputs X and T where X is an input matrix of input data and T in an input matrix of target data. For the code below, the energydata_complete file from above was used to generate X and T. Additionally, trainNNs takes a trainFraction which splits the X and T input matricies into test data and train data. If 0.8 is passed as the value for trainFraction, 80% of the data will be used as training data and the remaining 20% will be used as test data. \n",
    "\n",
    "The hiddenLayerStructures is assumed a list containing lists that are hidden layer structures. This code block will be executed once for each item in this list. The neural network will be trained and tested using each of the hidden layer structure's passed. For instance, if the network structure array passed is:\n",
    "<center>```[[1], [20, 20], [100, 50, 2, 50, 100]]```</center><br />\n",
    "The code block will be executed 3 times. The first time using one hidden layer with one with one unit, the second will be 2 hidden layers with 20 units each, and the third will be 5 hidden layers, two with 100 units, two with 50 units, and one with 2 units.\n",
    "\n",
    "Each neural network is trained ```numberRepetitions``` times. For each training session, the RMSE or root mean square error is calculated for both training and testing data and stored in a test or train array `numberRepetitions` in size.\n",
    "\n",
    "trainNNs returns a list containing four items:\n",
    "* The hidden layer structure (as a list)\n",
    "* A list of training data performance for each repetition (list containing RMSE of training data)\n",
    "* A list of testing data performance for each repetition (list containing RMSE of testing data)\n",
    "* The number of seconds it took to run this many repetitions for this network structure.\n",
    "\n",
    "For each hidden layer structure passed in the `hiddenLayerStructures` argument\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import mlutils as ml\n",
    "import numpy as np\n",
    "import neuralnetworks as nn\n",
    "\n",
    "def trainNNs(X, T, trainFraction, hiddenLayerStructures, numberRepetitions, numberIterations, classify=False):\n",
    "    results = []    \n",
    "    for hiddenLayer in hiddenLayerStructures:\n",
    "        res = []\n",
    "        res.append(hiddenLayer)\n",
    "        rmseTest = []\n",
    "        rmseTrain = []\n",
    "\n",
    "        start = time.time()\n",
    "        for n in range(numberRepetitions):\n",
    "            Xtrain,Ttrain,Xtest,Ttest = ml.partition(X, T,  (trainFraction, 1-trainFraction), classify)\n",
    "            # Neural Net takes Num Input, Num hidden Units, Num output\n",
    "            hlSize = 1 if isinstance(hiddenLayer, int) else len(hiddenLayer)\n",
    "            nnet = nn.NeuralNetwork(Xtrain.shape[1], hlSize, Ttrain.shape[1])\n",
    "            nnet.train(Xtrain, Ttrain, numberIterations)\n",
    "\n",
    "            if classify == False:\n",
    "                rmseTest.append(round(np.sqrt(np.mean(nnet.use(Xtest)-Ttest)**2), 2))\n",
    "                rmseTrain.append(round(np.sqrt(np.mean((nnet.use(Xtrain)-Ttrain)**2)), 2))\n",
    "            else:\n",
    "                rmseTest.append(np.sum(nnet.use(Xtest) != Ttest) / Ttest.shape[0])\n",
    "                rmseTrain.append(np.sum(nnet.use(Xtrain) != Ttrain) / Ttrain.shape[0])\n",
    "                \n",
    "        end = time.time() - start\n",
    "        end = round(end, 2)\n",
    "        res.append(rmseTrain)\n",
    "        res.append(rmseTest)\n",
    "        res.append(end)\n",
    "        results.append(res)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data file\n",
    "This function reading in data in the file name passed. This function handles double quotes by removing them entirely, and splits each line on `,` (hence csv...) and stores each line in a list. The first and last two columns of this data file are not used thus the slicing of ```[1:-2]``` in the code below. The loadFrogs function returns Xanuran, Tanuran similar to X and T mentioned above, but also returns a list of species names. If a data item is classified as 0, the species will be `names[0]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataFile(filename):\n",
    "    names = []\n",
    "    data = []\n",
    "    with open(filename, 'r') as f:\n",
    "        names = f.readline().replace(\"\\\"\", \"\").split(\",\")\n",
    "        for line in f:\n",
    "            temp = line.replace(\"\\\"\", \"\").split(\",\")\n",
    "            temp = [float(item.strip()) for item in temp[1:-2]]\n",
    "            data.append(temp)\n",
    "\n",
    "    dataNP = np.array(data)\n",
    "    return names[1:-2], dataNP\n",
    "\n",
    "def loadFrogs(filename):\n",
    "    Xanuran = [] \n",
    "    Tanuran = []\n",
    "    names = []\n",
    "    with open(filename, 'r') as f:\n",
    "        f.readline() # ignore first line\n",
    "        for line in f:\n",
    "            temp = line.split(\",\")\n",
    "            tempX = temp[1:22]\n",
    "            counter = 0\n",
    "            for i in tempX:\n",
    "                tempX[counter] = float(i)\n",
    "                counter += 1\n",
    "            Xanuran.append(tempX)\n",
    "            if temp[24] not in names:\n",
    "                names.append(temp[24])\n",
    "            Tanuran.append([names.index(temp[24])])\n",
    "    return np.array(Xanuran), np.array(Tanuran), names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize\n",
    "This method takes in the results as discussed in the Training Neural Networks cell above. For each item in the parameter `results`, this function will compute the mean of each item in the training data performance, testing data performance, and time. The first hidden layer structure is returned but can be ignored as it has no statistical value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(results):\n",
    "    res = []\n",
    "    for item in results:\n",
    "        temp = []\n",
    "        temp.append(item[0])\n",
    "        trainMean = 0\n",
    "        testMean = 0\n",
    "        for train in item[1]:\n",
    "            trainMean += train\n",
    "        trainMean /= len(item[1])\n",
    "        temp.append(trainMean)\n",
    "        for test in item[2]:\n",
    "            testMean += test\n",
    "        testMean /= len(item[2])\n",
    "        temp.append(testMean)\n",
    "        temp.append(item[3])\n",
    "        res.append(temp)\n",
    "    return res\n",
    "\n",
    "def bestNetwork(summary):\n",
    "    min = float('inf')\n",
    "    counter = 0\n",
    "    min_index = 0\n",
    "    for item in summary:\n",
    "        if item[2] < min:\n",
    "            min = item[2]\n",
    "            min_index = counter\n",
    "        counter += 1\n",
    "    return summary[min_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Experiment\n",
    "The neural network will be trained and tested without classification (using regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: [1, 0.44, 0.45000000000000001, 2.46]\n"
     ]
    }
   ],
   "source": [
    "X = np.arange(10).reshape((-1,1))\n",
    "T = X + 1 + np.random.uniform(-1, 1, ((10,1)))\n",
    "\n",
    "# Train neural network\n",
    "result = trainNNs(X, T, 0.8, [0, 1, 2, 10, [10, 10], [5, 5, 5, 5], [2]*5, [100, 50, 2, 50, 100], [16, 16], [1, 2, 3]], 50, 400, classify=False)\n",
    "summ = summarize(result)\n",
    "print(\"Best: \", end=\"\")\n",
    "print(bestNetwork(summ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "The first item in the above is the best hidden layer structure, the second item is the training data error, and the third item is the testing data error percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xenergy shape: (19735, 24)\n",
      "Tenergy shape: (19735, 2)\n",
      "[[0, 69.974999999999994, 0.53200000000000003, 10.07], [5, 70.441999999999993, 0.75700000000000001, 10.37], [[5, 5], 66.543000000000006, 0.65199999999999991, 16.85], [[10, 10], 66.193000000000012, 0.96799999999999997, 17.22]]\n",
      "Best: [0, 69.974999999999994, 0.53200000000000003, 10.07]\n"
     ]
    }
   ],
   "source": [
    "# Read in data file\n",
    "names, data = loadDataFile('energydata_complete.csv')\n",
    "\n",
    "# Store X and T\n",
    "Xenergy = np.array([item[2:] for item in data])\n",
    "Tenergy = np.array([item[:2] for item in data])\n",
    "\n",
    "# Names\n",
    "Xnames = np.array(names[2:])\n",
    "Tnames = np.array(names[:2])\n",
    "\n",
    "print(\"Xenergy shape: \", end=\"\")\n",
    "print(Xenergy.shape)\n",
    "print(\"Tenergy shape: \", end=\"\")\n",
    "print(Tenergy.shape)\n",
    "\n",
    "# Train neural network\n",
    "result = trainNNs(Xenergy, Tenergy, 0.8, [0, 5, [5, 5], [10, 10]], 10, 100)\n",
    "summ = summarize(result)\n",
    "print(summ)\n",
    "print(\"Best: \", end=\"\")\n",
    "print(bestNetwork(summ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Experiment\n",
    "The neural network will be trained and testing using classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1.0, 1.0, 1.07], [5, 1.0, 1.0, 1.02], [[5, 5], 1.0, 1.0, 1.61]]\n"
     ]
    }
   ],
   "source": [
    "Xanuran, Tanuran, names = loadFrogs('Frogs_MFCCs.csv')\n",
    "results = trainNNs(Xanuran, Tanuran, 0.8, [0, 5, [5, 5]], 5, 100, classify=True)\n",
    "print(summarize(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing summarize([[[1,1], [1.2, 1.3, 1.4], [2.2, 2.3, 2.4], 0.5], [[2,2,2], [4.4, 4.3, 4.2], [6.5, 6.4, 6.3], 0.6]])\n",
      "\n",
      "--- 10/10 points. Correctly returned [[[1, 1], 1.3, 2.3000000000000003, 0.5], [[2, 2, 2], 4.3, 6.3999999999999995, 0.6]]\n",
      "\n",
      "Testing bestNetwork([[[1, 1], 1.3, 2.3, 0.5], [[2, 2, 2], 4.3, 1.3, 0.6]])\n",
      "\n",
      "--- 10/10 points. Correctly returned [[2, 2, 2], 4.3, 1.3, 0.6]\n",
      "\n",
      "X = np.random.uniform(-1, 1, (100, 3))\n",
      "T = np.hstack(((X**2 - 0.2*X**3).sum(axis=1,keepdims=True),\n",
      "               (np.sin(X)).sum(axis=1,keepdims=True)))\n",
      "result = trainNNs(X, T, 0.7, [0, 5, 10, [20, 20]], 10, 100, False)\n",
      "\n",
      "--- 20/20 points. Correct.\n",
      "\n",
      "Testing bestNetwork(summarize(result))\n",
      "\n",
      "--- 20/20 points. You correctly found that network [20, 20] is best.\n",
      "\n",
      "A6 Execution Grade is 60/60\n",
      "\n",
      "======================= The regression data set =======================\n",
      "\n",
      "--- _/5 points. Read the data in energydata_complete.csv into variables Xenergy and Tenergy.\n",
      "\n",
      "--- _/5 points. Train some networks by calling the NeuralNetwork constructor and train method and plot the error trace to help you decide now many iterations might be needed.\n",
      "\n",
      "--- _/5 points. Try at least 10 different hidden layer structures using trainNNs.\n",
      "\n",
      "--- _/5 points. Train another network with your best hidden layer structure on 0.8 of the data and test it on remaining 0.2 of the data. Plot the predicted and actual Appliances energy use, and the predicted and actual lights energy use, in two separate plots. Discuss what you see.\n",
      "\n",
      "======================= Classification data set =======================\n",
      "\n",
      "--- _/5 points. Read the data in Frogs_MFCCs.csv into variables Xanuran and Tanuran.\n",
      "\n",
      "--- _/5 points. Train some networks by calling the NeuralNetwork constructor and train method and plot the error trace to help you decide now many iterations might be needed.\n",
      "\n",
      "--- _/5 points. Try at least 10 different hidden layer structures using trainNNs.\n",
      "\n",
      "--- _/5 points. Train another network with your best hidden layer structure on 0.8 of the data and test it on remaining 0.2 of the data. Plot the predicted and actual Appliances energy use, and the predicted and actual lights energy use, in two separate plots. Discuss what you see.\n",
      "\n",
      "A6 Notebook Grade is __/40\n",
      "\n",
      "A6 FINAL GRADE is __/100\n"
     ]
    }
   ],
   "source": [
    "%run -i \"A6grader.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
